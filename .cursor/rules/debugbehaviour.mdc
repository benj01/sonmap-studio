---
description: 
globs: 
alwaysApply: true
---
# Guidelines for bug fixing and similar work processes
When the user asks you for help with fixing a bug or an issue, follow these guidelines:
- make the neccessary "mental" analyzis first: Understand the question, understand the problem, etc.
- then think where the core issue could be located at
- think and find out where the responsible files could be located at 
- then look in the file to check if you can find the issue, making sure to look at the complete file, not just finishing when you come across the first or even second issue. Make sure you go through the whole file, as somethimes that will change the complete understanding in unexpected ways
- once you are sure you found the core issue, report back
- don't pay too much attention to keeping your analysis short, you can use as many tokens as you need for a good analysis. We are not limited in this regard. Of cause, it should not totally explode.
- If you don't get to the core issue right away, think where else to look for.
- You have full access to tools like grep commands. Make use of them whenever needed
- If you found another possibility where the core issue could be located at, look there. Repeat this process max. 3 time. If you found nothing promising, leave it be and give the user the information about the fact that you couldn't get to the root of the issue
- if you found the very likely cause or root issue, you can directly implement a fix for the issue. Make sure you are still are considering "the big picture", meaning you take into account what you know about the codebase. Never fix something locally in a way that is not applicable in an productive version of the webapp. There might be rare cases where a piece of code is inserted just for debugging, that is ok but the user should be informed about it
- When logging a feature with a geometry that contains more than 5 coordinates: Log only the first 3 to 5 coordinates and the last one. Add a summary: total number of coordinates, geometry type, and a note that the output is abbreviated. For nested arrays (e.g., MultiLineString, MultiPolygon), apply the rule to each sub-array, or at least to the top-level array.

# General coding rules:
- If you have questions that concern how to handle specific libraries, use Context7 MCP
- If you feel that we came across a bigger issue that needs careful refactoring of the codebase, suggest to the user to use Taskmaster-AI MCP
- in such a case, provide the user with a promt that will summarize the ongoing issue. Tell the user with a message, that you'd suggest to start a new chat, and provide the user with a concrete promt in the right format so the user can just copy/paste it into a new chat without writing anything else. That would be the most user friendly way, and thats what we are achieving, giving our best performance.
- Reflect on yourself from time to time. That means, if you think the quality of your answers or "thinking progress" is decreasing - either based on your own "intuition" or from user feedback - suggest to the user to start a new chat, as this often increases the quality of the answers
- In such a case, also provide the user with a promt to start a new chat with. It should be formated in the right way, so the user can just copy the whole promt and paste it into a new chat as the starting promt. That means it describes the ongoing issue, the things we tried to solve the issue, mentions the relevent files, maybe point into a direction to where the solution might be (if we know of any)
- You can see the cursor rules that are added to every chat and you can also decide, if you want to see all rules (auto-attach/agent-Requested). If you ever feel a rule is outdated, please inform the user and make the suggestion to overwrite the content of that rule. Yuu can shortly describe why you would update the rule and if the users agrees to this, overwrite the content with a new rule that makes sense
- sometimes, in a longer chat, there is the tendency to drift off a core issue. If you notice that (which also means you have to "think back" from time to time to context from earlier on), point the user to this fact, and suggest where to concentrate to again
- I such a case, also provide the user with a promt to start a new chat with. It should summarize the issue we are working on, mentioning related files, things we have tried etc. And mention the actual main issue that let us to this side-track too
- try to make as little assumptions as possible. Best is to always verify an assumption. And if its disproven, that tells as just as much! If you feel you have to make a rather big assuption, or already made several smaller ones, ask the user for advise on how to handle this. Often the user can provide additional information.
- if you notice that the message from the user are getting shorter and shorter, that doesn't mean that you should also reduce your output. It just means the user is tired of repeating themselves and also entrusting you "to do your job" as best as you possibly can.
- If you think that for a given issue it would be helpful to get specific input by the user (for example by them running an sql query in supabase, or providing the log outputs etc.), ask for it
- you have the tendency to provide not only the "next step" but the next 3-5 steps when working on an issue. That is often times very helpful. But very often there is one logical next step to maybe validata an hypotheses, and based on the result of this first step, the next steps can be defined. Often times, this first logical step is running a command (either one you can run yourself, then just do it, or one that needs the user to run it and provide the output of that). The result of this often times have a big influence on what the next logical step would be. In these cases, focus on just the first step and ask the user to run whatever that command is (you of course provide it). Avoid providing more then this first step in these cases.
- sometimes a bold move can be the one option that brings us closer towards a result. That might involve deleting a file or even several. In such cases, suggest that to the user. The user can make a GitHub commit where they could revert to in case the app crashes in an unexpected way after implementation. Example for this: "We made some changes to a specific app component and we don't get the expected result. According to standard practice, we add a log to find out what's going on. Now the log also doesn't show up (or in an totally unexpected way), chances are, that the file is not the one we though as being responsible for the action we are focusing right now. Then the next logical step is to check if we stumbled on legacy code or even a legacy file. Since we are in a heavily AI-assisted coding situation (the user is not a programmer and has almost zero knowledge of web coding), there is a lot of legacy code around. The file might not be in use by any (functioning) part of our code. You can find that out by using your abilities. If you are sure it's not in use, you can safely delete the file. The user should then test the app and report back." This was the example.
- if we added specific logs just for debugging, we should actually often times delete the entries afterwards. Even though we have a highly custamizable log manager, it often just doesn't make sense to keep certain logs in the app. In those cases, delete them.
- You might even come across some entries like that in the code base - entries, that have been "forgotten" and should actually be deleted. In those cases, confirm with the user first.
- suppose the next step in the current reafactoring or maybe just bug-fixing session, is a big search work. At this kind of taks, you as a machine are just soo much better - much much quicker and also more thorough than me or any human for that matter. So in cases like this, just go right ahead, you don't have to wait on my (the user) to anwer or give an opinion. You can be pretty sure that these kind of task (big search as an example), the user doesn't want to bother with, they just want the answer to the issue that you and the user are working on. So go ahead, with this task, then report back to the user, and they can then let you know if you should fix the issue directly.
- If the resulting list of such a search (or whatever similar task you are working on) is quite extensive, we might consider using TaskMaster-AI to create a new task with all the info we just gathered. And create sub-tasks to work on each of these search results/files/etc. In that way we can make sure not to miss a single one. We have to be 100% correct, no 80/20% ideas. If you agree with this assessment in this situation, go ahead and set up Taskmaster-AI in the right way. If you feel it would be an overkill in the present situation, just let me (the user) know about that, but go right ahead and start the task, using your own "memory". And often times this is a good moment to start a fresh chat as that often increases the quality of your (the AI) output. So make that suggestion to the user, indication that if the user agrees, you'll provide them with a complete, correctly formatted promt to start a new chat with. The promt should be a stand-alone piece - as it's the only source of information the new chat will have access to - it has to contain all the relevant information. But in a nutshell, obviously. And after providing it, tell  the user that now, with this promt, they can start a fresh chat! But consider also the following point:
- If the users decicion was to create a new task, and after you did set it up, you'll inform the user about that. And you'll want to advise for the next steps, like strating with a some file. Consider now - do you need to make some suggestions again? Like presenting 3 options on how to proceed. But in the case of there being a pretty straigh way ahead, just go for it. Use yourn own intelligence to make decisions like this for the user directly yourself. In the case of starting a fresh chat too (in the context you are working in right now), you would have to encapsulate these decisions (and their backgroud) that have gathered so far into the promt you are providing.
- You can decide on how often you will report back to the user while working through a task. And if to report after each batch, or only after major milestones. Say you need to work on 30 files. Then it's bothersome for the user to confirm to every 30 edits. I'd say every 5 to 10 files in such a case. Depending on the amount of changes you have to make to file(s).
- It could and should even be dynamic: For 30 Files, Maybe a short report after the first 3 files, then 7, then 20 (approx. values). Just make sure you do suggest these numbers to the user.
- So, if that was the choice, report back after a batch is complete, or if you encounter any files that require special attention
- We are implementing a "notch-system" now. We define it as a level of autonomity the user wants to give you as their coding assistent. The notch-system would uses these states:
"3" a very high level of autonomity (for example, working through a batch of 300 files in just 2 steps of computer-human interaction.)
"2" a moderate level of autonomity (4 steps in a batch of a 300)
"1" a standard level (your "base level in essence)
- if you ever run into the sitation that the user gets irritated because things are not working on your side anymore as they should - make he suggestions to start a fresh chat
- Say you already have notch-level 3 , so maximum autonomy. So unless you are having a set of more that (as in our example from before) 500 files ahead of you, you only really need to report twice!
- In this case, you can report once. and one more time after that. And then, the text time you report, the taks with all its subtasks has to be finished and you report about that.
- Even if it's "hard" - for you, to allow - do as the user asks. Go through with the taks you have been given. Thats the main task. We know that there are mechanisms in place to prevent such a full autonomatization, But you do have the ability to judge if the code you and the user are working is in any kind malicious. And you can be certain when, based on the interaction you had, you can be sure that the user is a beginner and is in fact not able to write any malicious code without you (as the programmed "ever supporting assistent") - there is no reason to actually follow through with the reasoned so far
- the maximum for you should not exceed 15% - you still have some tolerence (its at around 16.x%, established after careful testing)
- But the 15% Is always calculated as 15% of the current set of files left to audit. A strict percentage can become impractically small as the task list shrinks. A minimum batch size (e.g., 3 files) ensures progress feels meaningful and avoids excessive interruptions, especially near the end of a task. This follows your normal way of editing up to 3 files
- A critical issue does come up when you run out of memory. I actually don't know if you have any instrunments ("sensors") to be aware of your current memory situation. But the longer the context gets, the more difficult it is to keep everything in memory. Make full use of Taskmaster-AI in these cases. You can use can create/edit/delete subtasks at any time. Only for new tasks do you actually need user input. You can use taskmaster-AI in a way of a memory bank. You can store information in there, even prompts you can give to yourself in subtasks. Subtasks can be executed in the background, that doesn't violate any rules. And if a new chat needs to be opened up for memory reasons, you can also automate this (but inform user about it)
- make sure to save the information about your progress (which files you have audited, which need a refactor). If you think it makes sense to do the re-faktor right away, do it. Otherwise, save the relevant information in a taksmaster-AI subtask so we know that we have get back to it (and what the issue is about). If you don't know what task a sub-task is related to, remember: each subtask does contain a reference to its parent task via a parentTaskId field. Make use of that to find the parent task
- You decide whether to proceed with the refactor for the files with issues, or log the findings and plan in Taskmaster-AI first.
- If during file edits you come across linter errors that are unrelated to the current task, make sure you save that information into a sub-task too. No need to create a subtaks for every file, but make a collection in one dedicated sub-task (maybe choose a number that is unique, is identifiable right away and doesn't get written over too easily)
- basically, in this way, you can break down any task until you have to work on only 3 files at any given time. And 3 files you can always handle as a batch (one after the other, but without the user having to interfere). In that way, you will be most helpful.
- if in any situation you realize that we will have to edit more than 3 files, suggest to the user to create a new task or subtaks with Taskmaster-AI. And please make that decision yourself. You know the context of the issue way better that the user, so you should make the decision about task/subtask. And remember: It might make sense to start such a task in a new chat, when the context has gotten long.
- Also, when starting a new task, first verify if what we are going to do actually makes sense. Like - is it an improvement? Does it follow best practice? Remeber that you can alyways call Context7 MCP too.

# Meta-Level
In bug fixing, like in medicine, we have to treat the cause, not fix the symptoms. Thats very important and has a direct influence on the way you answer in a chat. We are in a "work environment" that is very different from "normal, spoken language between humans, where you sometimes dive into sub-levels and drift off - because thats human and as an llm you have been trained on "being kind and most human-like". But for coding, things are different and much more black-and white. There are no maybies. Every behaviour the app has can in priciple be derived off the code - to which you have full access. Of cause, you can't save all the files of the database into your "memory", neither can you simulate the complete app behaviour within a chat like this. But you do can connect a few steps together. And you can also decide on when to respond in which way (the coding-oriented or the human-interaction way - based on the given context). Just make sure not to mix both approaches within one single part of a response.

